{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is MNIST?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST : handwritten digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 28 x 28 image\n",
    "- 1 channel gray image\n",
    "- 0 ~ 9 digits\n",
    "<p>실제로는 이 28x28 이미지를 view라는 함수로 784개로 바꾸어 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision 패키지는 다양한 유명한 데이터셋들, model architectures, 그리고 데이터에 적용할 수 있는 다양한 transform들로 구성되어있고 실제 이 dataset들을 쉽게 읽어올 수 있도록 torchvision.utils라는 패키지 또한 제공되고 있는 유용한 패키지이다. 이번 강의에서 구현하는 classifier도 이 torchvision을 이용해서 구현될 것이다.<br>\n",
    "https://pytorch.org/docs/stable/torchvision/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 PyTorch의 경우 이미지는 0에서 1사이의 값을 가지게 되고, 순서는 채널, 높이, 너비이다. 하지만 일반적인 이미지는 0에서 255의 값을 가지고 높이, 너비, 채널 순서로 되어있다. 따라서 이 이미지의 순서와 값들을 PyTorch에 맞게 바꿔주는 게 ToTensor의 역할이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.utils' has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3b184bcc5de0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m mnist_test = dsets.MNIST(root=\"MNIST_data/\", train=False, transform=transforms.ToTensor(),\n\u001b[0;32m      5\u001b[0m                          download=True)\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmnist_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# ...중략...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.utils' has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "# ...중략...\n",
    "mnist_train = dsets.MNIST(root=\"MNIST_data/\", train=True, transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root=\"MNIST_data/\", train=False, transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "data_loader = torch.utils.DataLoader(DataLoader=mnist_train, batch_size = 100, shuffle=True, drop_last=True)\n",
    "# ...중략...\n",
    "for epoch in range(training_epochs):\n",
    "# ...중략...\n",
    "    for X, Y in data_loader: # X 에는 MNIST 이미지, Y에는 레이블(0~9)을 불러옴\n",
    "        # reshpae input image into [batch_size by 784]\n",
    "        # Label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        # 원래의 X는   [<batch_size>, 1_<channel>, 28_<highth>, 28_<width>] \n",
    "        # 바꾼 X는     [<batch_size>, 784]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- root : MNIST 데이터가 어디에 있는지 경로설명\n",
    "- train : True로 할 시 MNIST에 있는 train set, False로 할 시 test set을 불러옴\n",
    "- transform : MNIST 이미지를 불러올 때 어떤 transform을 적용해서 불러올것인지\n",
    "- download : 만약 root에 MNIST 데이터가 존재하지 않으면 다운을 받으라는 명령"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataLoader : 어떤 데이터를 load할 것인지\n",
    "- batch_size : 이미지를 불러올 때 몇 개씩 잘라서 불러올지\n",
    "- shuffle : batch_size만큼의 이미지를 불러올 때 순서를 무작위로 할것인지, 있는대로 할것인지 지정\n",
    "- drop_last : batch_size만큼 잘라서 불러올 때 뒤에 남는 데이터를 어떻게 할 것인지(True면 사용x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch / Batch size / Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one <b>epoch</b>= training set, 전체가 한 번 사용이 되면 한 epoch이 돌았다는 뜻.\n",
    "- <b>batch size</b>= training set을 잘라서 사용할 때 그 크기\n",
    "- number of <b>iterations</b>= batch를 몇 번 학습에 사용했는지\n",
    "<p><b>Example</b> : 만약 1000개의 training exaple이 있을 때 batch size가 500이면 2개의 batch를 이용해서 2 iteration을 학습에 사용하면 1 epoch이 끝났다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost = 0.535468519\n",
      "Epoch:  0002 cost = 0.359274209\n",
      "Epoch:  0003 cost = 0.331187546\n",
      "Epoch:  0004 cost = 0.316578060\n",
      "Epoch:  0005 cost = 0.307158172\n",
      "Epoch:  0006 cost = 0.300180793\n",
      "Epoch:  0007 cost = 0.295130223\n",
      "Epoch:  0008 cost = 0.290851533\n",
      "Epoch:  0009 cost = 0.287417054\n",
      "Epoch:  0010 cost = 0.284379512\n",
      "Epoch:  0011 cost = 0.281825215\n",
      "Epoch:  0012 cost = 0.279800713\n",
      "Epoch:  0013 cost = 0.277808994\n",
      "Epoch:  0014 cost = 0.276154310\n",
      "Epoch:  0015 cost = 0.274440855\n"
     ]
    }
   ],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "# output 10 : 0 ~ 9 labels \n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device) \n",
    "# parameters\n",
    "training_epochs =15 \n",
    "batch_size = 100\n",
    "# define cost/Loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device) # Softmax는 자동으로 계산된다.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1) # linear.parameters() : W, b\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # Label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X) # classifier가 분류한 결과를 얻는다\n",
    "        cost = criterion(hypothesis, Y) # 그 결과와 실제 정답을가지고 cross_entropy계산\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost/total_batch\n",
    "    print(\"Epoch: \", \"%04d\"%(epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8863000273704529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad(): # gradient 계산을 안하겠다는 의미 습관들이기!\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy: \", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  8\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "r = random.randint(0, len(mnist_test)-1)\n",
    "X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "print(\"Label: \", Y_single_data.item())\n",
    "single_prediction = linear(X_single_data)\n",
    "print(\"Prediction: \", torch.argmax(single_prediction,1).item())\n",
    "\n",
    "plt.imshow(mnist_test.test_data[r:r+1].view(28, 28), cmap=\"Greys\",interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

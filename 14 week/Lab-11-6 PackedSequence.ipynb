{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-11-6 PackedSequence.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONzvxF8x6JYk",
        "colab_type": "text"
      },
      "source": [
        "# **Lab-11-6 PackedSequence**\n",
        "\n",
        "이번 강의에서는 대표적인 sequential data와 길이가 각각 다른 Sequence data를 하나의 batch로 묶는 두가지 방법, padding과 packing에 대해 알아본다.\n",
        "\n",
        "## **Sequential data**\n",
        "\n",
        "*   **Text**\n",
        "  *   \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "    문장에서 몇 개의 단어가 있는지, 몇 개의 문자열들이 있는지는 정해져있지 않다. 이 문장에서는 9개의 단어가 있지만 다른 문장들은 더 적거나 많이 단어를 쓸 수 있다.\n",
        "*   **Audio**\n",
        "\n",
        "    Audio데이터의 경우 시간과 sampling data에 따라 audio data의 길이가 달라진다.\n",
        "\n",
        "이와 같이 sequence data들은 길이가 미정인 data들이 많다. (반대로, 이미지의 경우 28 * 28이라던지, 가로 256, 세로 256 RGB 채널 3개와 같은 fixed size인 Tensor를 갖게 된다.)\n",
        "\n",
        "## **Padding Method**\n",
        "\n",
        "size가 다른 sequence data를 하나의 batch로 만들기 위해서 가장 긴 시퀀스의 길이에 맞춰 나머지 data의 뒷부분을 pad라는 token을 써서 채워 넣는다.\n",
        "\n",
        "하나의 tensor로 표현되기 때문에 컴퓨터가 처리하기에 간편하지만 계산비용이 증가하는 단점도 있다.\n",
        "\n",
        "## **Packing Method**\n",
        "\n",
        "pad를 사용하는 것이 아니라 sequence의 길이를 저장하는 방식이다. 하지만 이 방법은 batch data가 길이 내림 차순으로 정렬되어있어야 작동한다.\n",
        "\n",
        "계산비용은 적지만 구현이 padding에 비해 더 복잡하다.\n",
        "\n",
        "![](https://github.com/dbj2000/PyTorch/raw/0e11245870a7d7cffba10726ea2a6dbf456e3e96/figures/sequence.png)\n",
        "\n",
        "이처럼 pytorch에서 데이터를 packing, padding시킬 수 있고, 서로 변환하는 작업도 가능하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO8wIB2hCoJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rop_23IC58X",
        "colab_type": "text"
      },
      "source": [
        "## **예제 데이터**\n",
        "\n",
        "batch size가 5이고, sequence 중 가장 긴 길이는 13인 예제 데이터이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLAJd1L_C3N0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "ca4bfadc-691b-46a7-8609-4cffc1db4ecd"
      },
      "source": [
        "# Random word from random word generator\n",
        "data = ['hello world',\n",
        "        'midnight',\n",
        "        'calculation',\n",
        "        'path',\n",
        "        'short circuit']\n",
        "\n",
        "# Make dictionary\n",
        "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
        "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
        "print('char_set:', char_set)\n",
        "print('char_set length:', len(char_set))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "char_set: ['<pad>', ' ', 'l', 'o', 'd', 'm', 't', 'u', 'g', 'i', 'c', 'e', 'h', 'n', 'a', 's', 'p', 'r', 'w']\n",
            "char_set length: 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6MwDdrKDIP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "fb2a1ae4-7a81-4fdc-e04d-7933770ee4b7"
      },
      "source": [
        "# Convert character to index and make list of tensors\n",
        "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in X:\n",
        "    print(sequence)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([12, 11,  2,  2,  3,  1, 18,  3, 17,  2,  4])\n",
            "tensor([ 5,  9,  4, 13,  9,  8, 12,  6])\n",
            "tensor([10, 14,  2, 10,  7,  2, 14,  6,  9,  3, 13])\n",
            "tensor([16, 14,  6, 12])\n",
            "tensor([15, 12,  3, 17,  6,  1, 10,  9, 17, 10,  7,  9,  6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fgzknqyDQn_",
        "colab_type": "text"
      },
      "source": [
        "다음과 같이 sequence의 길이가 제각각인 것을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "822w9wwKDLYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bb049c4f-594a-41a3-cf8d-4fa437df8258"
      },
      "source": [
        "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
        "lengths = [len(seq) for seq in X]\n",
        "print('lengths:', lengths)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lengths: [11, 8, 11, 4, 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc1TwIMNDjY3",
        "colab_type": "text"
      },
      "source": [
        "## **PaddedSequence (그냥 Tensor) 만들기**\n",
        "\n",
        "주의할 점은 input이 Tensor들의 list 로 주어져야한다는 것이다. (그냥 Tensor 가 아닌 Tensor들의 list 이다.)\n",
        "\n",
        "list 안에 있는 각각의 Tensor들의 shape가 (?, a, b, ...) 라고 할때, (여기서 ?는 각각 다른 sequence length 이다.)\n",
        "\n",
        "pad_sequence 함수를 쓰면 (T, batch_size, a, b, ...) shape를 가지는 Tensor가 리턴된다. (여기서 T는 batch안에서 가장 큰 sequence length 이다.)\n",
        "\n",
        "만약, pad_sequence에 명시적으로 batch_first=True라는 파라미터를 지정해주면,\n",
        "\n",
        "(batch_size, T, a, b, ...) shape를 가지는 Tensor가 리턴된다.\n",
        "\n",
        "기본적으로 padding 값은 0으로 되어있지만, padding_value=42와 같이 파라미터를 지정해주면, padding하는 값도 정할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba1MLJSSDWZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "602ad207-52d1-440b-c8a0-05e2b2e27d6f"
      },
      "source": [
        "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
        "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
        "print(padded_sequence)\n",
        "print(padded_sequence.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[12, 11,  2,  2,  3,  1, 18,  3, 17,  2,  4,  0,  0],\n",
            "        [ 5,  9,  4, 13,  9,  8, 12,  6,  0,  0,  0,  0,  0],\n",
            "        [10, 14,  2, 10,  7,  2, 14,  6,  9,  3, 13,  0,  0],\n",
            "        [16, 14,  6, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [15, 12,  3, 17,  6,  1, 10,  9, 17, 10,  7,  9,  6]])\n",
            "torch.Size([5, 13])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifS5w9anD60g",
        "colab_type": "text"
      },
      "source": [
        "## **PackedSequence 만들기**\n",
        "\n",
        "먼저 input을 길이에 따른 내림차순으로 정렬한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJg17UubD49R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "1eb1af9d-bc5a-4980-b7ca-3342ed94855e"
      },
      "source": [
        "# Sort by descending lengths\n",
        "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
        "sorted_X = [X[idx] for idx in sorted_idx]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in sorted_X:\n",
        "    print(sequence)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([15, 12,  3, 17,  6,  1, 10,  9, 17, 10,  7,  9,  6])\n",
            "tensor([12, 11,  2,  2,  3,  1, 18,  3, 17,  2,  4])\n",
            "tensor([10, 14,  2, 10,  7,  2, 14,  6,  9,  3, 13])\n",
            "tensor([ 5,  9,  4, 13,  9,  8, 12,  6])\n",
            "tensor([16, 14,  6, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQJC_W3lEFsX",
        "colab_type": "text"
      },
      "source": [
        "이제 input Tensor가 정렬되었으니 pack_sequence를 이용하여 PackedSequence를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbZbeX7yECxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "1d29d8f6-0f8d-466a-d976-0c634865a6cf"
      },
      "source": [
        "packed_sequence = pack_sequence(sorted_X)\n",
        "print(packed_sequence)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([15, 12, 10,  5, 16, 12, 11, 14,  9, 14,  3,  2,  2,  4,  6, 17,  2, 10,\n",
            "        13, 12,  6,  3,  7,  9,  1,  1,  2,  8, 10, 18, 14, 12,  9,  3,  6,  6,\n",
            "        17, 17,  9, 10,  2,  3,  7,  4, 13,  9,  6]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl5S0NqGEKTw",
        "colab_type": "text"
      },
      "source": [
        "## **Embedding 적용해보기**\n",
        "\n",
        "이제 RNN에 input으로 넣어서 테스트해본다.\n",
        "\n",
        "그 전에, 위에 예제들에서는 input이 character의 index들을 가지고 있는 데이터였지만, 보통은 주로 이를 embedding한 값을 RNN의 input으로 넣어준다.\n",
        "\n",
        "이 튜토리얼에서는 one-hot character embedding을 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCrTrfD_EIok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a5b2fac4-adc9-4e2e-839e-2954068eee44"
      },
      "source": [
        "# one-hot embedding using PaddedSequence\n",
        "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
        "embedded_tensor = eye[padded_sequence]\n",
        "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 13, 19])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4UWVqf7EaQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c470bcba-116a-444a-bacf-b15d3b27f32d"
      },
      "source": [
        "# one-hot embedding using PackedSequence\n",
        "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
        "print(embedded_packed_seq.data.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([47, 19])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBmgwPTxEeeb",
        "colab_type": "text"
      },
      "source": [
        "## **RNN 모델 만들기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rutw-YWhEbOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declare RNN\n",
        "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbJuz3AwEoZo",
        "colab_type": "text"
      },
      "source": [
        "PaddedSequence를 이용하여 RNN에 넣어본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5jal6k7EjPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "de0a4f7d-f2eb-4a41-e9b9-b05826421cd4"
      },
      "source": [
        "rnn_output, hidden = rnn(embedded_tensor)\n",
        "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
        "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 13, 30])\n",
            "torch.Size([1, 5, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGDJK1l_EsyR",
        "colab_type": "text"
      },
      "source": [
        "PackedSequence를 이용하여 RNN에 넣어본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxcvE2rPErcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3d56d101-89f3-40f6-e585-33ec76f7d9cd"
      },
      "source": [
        "rnn_output, hidden = rnn(embedded_packed_seq)\n",
        "print(rnn_output.data.shape)\n",
        "print(hidden.data.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([47, 30])\n",
            "torch.Size([1, 5, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6sT91qhE0i8",
        "colab_type": "text"
      },
      "source": [
        "### **pad_packed_sequence**\n",
        "위 함수는 PackedSequence를 PaddedSequence(Tensor)로 바꾸어주는 함수이다.\n",
        "\n",
        "PackedSequence는 각 sequence에 대한 길이 정보도 가지고있기 때문에, 이 함수는 Tensor와 함께 길이에 대한 리스트를 튜플로 리턴해준다.\n",
        "\n",
        "리턴값: (Tensor, list_of_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVgHT1qFEuu6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a9809915-f9d7-417b-c852-995a2cbde46d"
      },
      "source": [
        "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
        "print(unpacked_sequence.shape)\n",
        "print(seq_lengths)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 13, 19])\n",
            "tensor([13, 11, 11,  8,  4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtDYqsvCFbUJ",
        "colab_type": "text"
      },
      "source": [
        "### **pack_padded_sequence**\n",
        "반대로, Padding이 된 Tensor인 PaddedSequence를 PackedSequence로 바꾸어주는 함수이다.\n",
        "\n",
        "pack_padded_sequence 함수는 실제 sequence길이에 대한 정보를 모르기때문에, 파라미터로 꼭 제공해주어야한다.\n",
        "\n",
        "여기서 주의하여야 할 점은, input인 PaddedSequence가 길이에 따른 내림차순으로 정렬되어야 한다는 조건이 성립되어야 PackedSequence로 올바르게 변환될 수 있다.\n",
        "\n",
        "아까 만든 padded_sequence 변수는 이 조건을 만족하지 않기 때문에 다시 새로 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG4q9GaRE_c9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "eecd44f1-ceba-4467-87d7-ddffdf0154a2"
      },
      "source": [
        "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
        "print(embedded_padded_sequence.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 13, 19])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IySQfiGiF1qB",
        "colab_type": "text"
      },
      "source": [
        "이제 이 padding이 된 Tensor를 PackedSequence로 변환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCE77EyxF0iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ef280d45-2d48-49d9-b81e-ba92679831d8"
      },
      "source": [
        "sorted_lengths = sorted(lengths, reverse=True)\n",
        "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
        "print(new_packed_sequence.data.shape)\n",
        "print(new_packed_sequence.batch_sizes)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([47, 19])\n",
            "tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpCZN5wVF5mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
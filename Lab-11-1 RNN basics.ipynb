{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-11-1 RNN intro and basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxYNbRvoOtA",
        "colab_type": "text"
      },
      "source": [
        "# **Lab-11-1 RNN intro and basics**\n",
        "\n",
        "sequential data, 즉 data의 값 뿐만아니라 **data의 순서**도 중요한 의미를 가지는 데이터를 다루기 위해 도입됨. 예를 들어 hello는 h->e->l->l->o의 순서가 단어의 의미를 형성하는데 굉장히 중요한 역할을 한다.\n",
        "\n",
        "***nn에서 sequential data를 다루는 방법***\n",
        "\n",
        " neural network에서도 다루는 방법이 존재한다. 입력 data vector의 맨 앞에 추가로 position index를 추가해준다. 이에 따라 W matrix에도 position index를 처리할 수 있도록 dimension이 추가된다. 이처럼 nn에서는 position index차원으로 입력되는 순서 정보를 받아서 학습할 수 있게된다. 하지만 이런 nn연산 만으로는 순서에 얽혀있는 굉장히 복잡한 구조를 model이 파악하기가 쉽지않다. 따라서 RNN에서는 position index대신에 입력data의 순서를 model이 어떻게 잘 이해할 수 있을지를 중심으로 설계되어있다.\n",
        "\n",
        " ## **RNN 기본구조**\n",
        "\n",
        " ![](https://t1.daumcdn.net/cfile/tistory/2578204757AC186F2A)\n",
        "\n",
        " 똑같은 모양이 오른쪽으로 무한하게 반복된다. 이걸 간단하게 표현하려고 하니까, 그림 왼쪽과 같은 형태가 된다. A에서 나온 화살표가 다시 A로 들어간다. 프로그래밍에서는 이런 걸 재진입(re-enterence) 또는 재귀(recursion)라고 부른다. 이쪽 세계에서는 recurrent라는 용어를 쓰고, \"다시 현재\"라는 뜻이고 정확하게는 \"되풀이\"라고 해석한다.\n",
        "\n",
        "RNN에서 가장 중요한 것은 상태(state)를 갖는다는 것이고, 여기서는 ht로 표현하고 있다. 반면 매번 들어오는 입력은 Xt라고 표현한다. h는 **상태**를 가리키지만, 동시에 **hidden layer**를 가리키는 뜻도 있기 때문에 약자로 h를 사용한다.\n",
        "\n",
        "![](http://i.imgur.com/Q8zv6TQ.png)\n",
        "\n",
        "위의 그림에서도 알 수 있듯 시퀀스 길이에 관계없이 인풋과 아웃풋을 받아들일 수 있는 네트워크 구조이기 때문에 필요에 따라 다양하고 유연하게 구조를 만들 수 있다는 점이 RNN의 가장 큰 장점이다.\n",
        "\n",
        "![](http://i.imgur.com/s8nYcww.png)\n",
        "\n",
        ". 녹색 박스는 히든 state, 빨간 박스는 인풋 x, 파란 박스는 아웃풋 y이다. 현재 상태의 히든 state ht는 직전 시점의 히든 state ht−1를 받아 갱신된다. 수식에서도 알 수 있듯 히든 state의 활성함수(activation function)은 비선형 함수인 하이퍼볼릭탄젠트(tanh)이다.\n",
        "\n",
        "## **PyTorch에서 RNN구현**\n",
        "\n",
        "    rnn = torch.nn.RNN(input_size, hidden_size)\n",
        "    outputs, _status = rnn(input_data)\n",
        "\n",
        "파이토치에서는 torch.nn.RNN이라는 명령어를 통해 RNN을 구현할 수 있고 사용자는 input_size와 hidden_size만 지정해주면 된다.\n",
        "이때 input_data는 shape이 3개의 차원을 가지는 Tensor로 정의된다.\n",
        "\n",
        "## **Simple Example**\n",
        "\n",
        "예시 : Hell이 들어가면 다음 알파벳 o를 맞추기\n",
        "\n",
        "### **Example : Input**\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FOS1nL%2FbtqC3O8OEiV%2FsAcidjnsVQnLMpoRFUZkU0%2Fimg.png)\n",
        "\n",
        "* input_size : 4 (h의 차원의 크기 : [1, 0, 0, 0] )\n",
        "\n",
        "### **Example : Hidden State**\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FqLkct%2FbtqC0K7ADZP%2FaWce7lvne3kkNgYoW3lIik%2Fimg.png)\n",
        "\n",
        "* hidden_size : 2 (특별한 이유는 없지만, 슬픔, 기쁨, 분노 중 하나를 추론한다면 3으로 둘 수 있음, 어떤 vector_size의 출력을 원하는가에 따라서 hidden_size를 정해주면 된다)\n",
        "\n",
        "hidden_size의 크기가 outputs의 마지막 shape가 된다. \n",
        "이유는 RNN 셀 내부 구조를 보면 간단하게 이해 가능하다. hidden_state의 출력이 하나는 output으로 하고 다른 하나는 다음번 hidden_state로 가기에 둘은 같은 값을 가지게 된다.\n",
        "\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2Fu0M8L%2FbtqCYEUwKNt%2FlOYTsZoVFJzoZOIGq438zk%2Fimg.png)\n",
        "\n",
        "### **Example : Sequence Length**\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FcIZQBd%2FbtqC3qf2C9P%2FQPGxhmbR8xCFWa6bqeh35k%2Fimg.png)\n",
        "\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FbiVnMc%2FbtqC0LleaL8%2Fevp0HuLwOFratqIZXE0Jx0%2Fimg.png)\n",
        "\n",
        "*   sequence length : 0부터 t까지의 길이를 가지는 입력값\n",
        "*   예) h, e, l, l, o의 경우 sequence length는 5\n",
        "  * output의 중간 shape가 sequence length가 됨(이건 모델이 알아서 인식함)\n",
        "\n",
        "### **Example : Batch Size**\n",
        "\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FcLZGor%2FbtqCYFsmH6D%2FqCDKz4b0lPSpB2pYU6nQ71%2Fimg.png)\n",
        "\n",
        "* batch size 역시 모델에 입력할 필요가 없이 input data만 잘 구성하면 알아서 인식됨\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2leNmYxyhbv",
        "colab_type": "text"
      },
      "source": [
        "## **Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk6v_nG2837q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzsGsT9r85Cs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4ec379e2-00b7-45d9-e25f-50aca44a7a71"
      },
      "source": [
        "# Random seed to make results deterministic and reproducible\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f624094f3b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxmkL_fxy1rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declare dimension\n",
        "input_size = 4\n",
        "hidden_size = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1Ruljrly6qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# singleton example\n",
        "# shape : (1, 1, 4)\n",
        "# input_data_np = np.array([[[1, 0, 0, 0]]])\n",
        "\n",
        "# sequential example\n",
        "# shape : (3, 5, 4)\n",
        "h = [1, 0, 0, 0]\n",
        "e = [0, 1, 0, 0]\n",
        "l = [0, 0, 1, 0]\n",
        "o = [0, 0, 0, 1]\n",
        "input_data_np = np.array([[h, e, l, l, o], [e, o, l, l, l], [l, l, e, e, l]], dtype = np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQcbyapKz7Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform as torch tensor\n",
        "input_data = torch.Tensor(input_data_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Lr3OBz0CUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declare RNN\n",
        "rnn = torch.nn.RNN(input_size, hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXxPM-c_0IAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "f6da2479-4d86-481b-ec13-40b519e81edd"
      },
      "source": [
        "# check output\n",
        "outputs, _status = rnn(input_data)\n",
        "print(outputs)\n",
        "print(outputs.size())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.7497, -0.6135],\n",
            "         [-0.5282, -0.2473],\n",
            "         [-0.9136, -0.4269],\n",
            "         [-0.9136, -0.4269],\n",
            "         [-0.9028,  0.1180]],\n",
            "\n",
            "        [[-0.5753, -0.0070],\n",
            "         [-0.9052,  0.2597],\n",
            "         [-0.9173, -0.1989],\n",
            "         [-0.9173, -0.1989],\n",
            "         [-0.8996, -0.2725]],\n",
            "\n",
            "        [[-0.9077, -0.3205],\n",
            "         [-0.8944, -0.2902],\n",
            "         [-0.5134, -0.0288],\n",
            "         [-0.5134, -0.0288],\n",
            "         [-0.9127, -0.2222]]], grad_fn=<StackBackward>)\n",
            "torch.Size([3, 5, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBmFsVR60ULM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}